import aiohttp
import asyncio
import hashlib
import time
from typing import Dict, List, Optional, Any
from bs4 import BeautifulSoup
from ncatbot.plugin import BasePlugin, CompatibleEnrollment
from ncatbot.core.message import GroupMessage
from urllib.parse import quote
import re
# å°è¯•å¯¼å…¥æ’ä»¶ç®¡ç†å™¨ï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›é»˜è®¤å®ç°
try:
    from PluginManager.plugin_manager import feature_required
except ImportError:
    def feature_required(feature_name=None, commands=None, require_admin=False):
        """ç®€å•çš„è£…é¥°å™¨æ›¿ä»£ç‰ˆæœ¬"""
        def decorator(func):
            return func
        return decorator
from utils.group_forward_msg import send_group_forward_msg_ws
from utils.config_manager import get_config, load_config
from utils.logger_config import get_logger

# è·å–æ—¥å¿—è®°å½•å™¨
_log = get_logger(__name__)

bot = CompatibleEnrollment

class MikanAnimeSearch(BasePlugin):
    name = "MikanAnimeSearch"
    version = "2.0.0"

    def __init__(self, event_bus=None, time_task_scheduler=None, debug=False, **kwargs):
        super().__init__(event_bus, time_task_scheduler, debug=debug, **kwargs)
        # ç¼“å­˜ç³»ç»Ÿ
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._cache_ttl = 600  # 10åˆ†é’Ÿç¼“å­˜

        # é¢‘ç‡é™åˆ¶
        self._user_last_request: Dict[int, float] = {}
        self._rate_limit_interval = 2.0  # 2ç§’é—´éš”

        # ç»Ÿè®¡æ•°æ®
        self._stats = {
            "total_searches": 0,
            "successful_searches": 0,
            "failed_searches": 0,
            "cache_hits": 0,
            "cache_misses": 0
        }

        # HTTPè¿æ¥å™¨é…ç½®
        self._connector = None
        self._session = None

    async def on_load(self):
        """æ’ä»¶åŠ è½½æ—¶çš„åˆå§‹åŒ–"""
        try:
            # åˆ›å»ºä¼˜åŒ–çš„HTTPè¿æ¥å™¨
            connector = aiohttp.TCPConnector(
                limit=15,  # æ€»è¿æ¥æ•°
                limit_per_host=8,  # å•ä¸»æœºè¿æ¥æ•°
                ttl_dns_cache=600,  # DNSç¼“å­˜10åˆ†é’Ÿ
                use_dns_cache=True,
                enable_cleanup_closed=True
            )

            # åˆ›å»ºHTTPä¼šè¯
            timeout = aiohttp.ClientTimeout(total=30, connect=10)
            self._session = aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1'
                }
            )

            _log.info(f"{self.name} v{self.version} æ’ä»¶å·²åŠ è½½")
            _log.info("HTTPè¿æ¥æ± å·²åˆå§‹åŒ–ï¼Œç¼“å­˜ç³»ç»Ÿå·²å¯åŠ¨")

        except Exception as e:
            _log.error(f"æ’ä»¶åŠ è½½å¤±è´¥: {e}")
            raise

    async def on_unload(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†"""
        try:
            if self._session:
                await self._session.close()
            _log.info(f"{self.name} æ’ä»¶å·²å¸è½½ï¼Œèµ„æºå·²æ¸…ç†")
        except Exception as e:
            _log.error(f"æ’ä»¶å¸è½½æ—¶å‡ºé”™: {e}")

    def _get_cache_key(self, query: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return hashlib.md5(query.encode('utf-8')).hexdigest()

    def _is_cache_valid(self, cache_entry: Dict[str, Any]) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        return time.time() - cache_entry['timestamp'] < self._cache_ttl

    def _cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        current_time = time.time()
        expired_keys = [
            key for key, entry in self._cache.items()
            if current_time - entry['timestamp'] >= self._cache_ttl
        ]
        for key in expired_keys:
            del self._cache[key]

        if expired_keys:
            _log.debug(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®")

    def _check_rate_limit(self, user_id: int) -> bool:
        """æ£€æŸ¥ç”¨æˆ·è¯·æ±‚é¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        last_request = self._user_last_request.get(user_id, 0)

        if current_time - last_request < self._rate_limit_interval:
            return False

        self._user_last_request[user_id] = current_time
        return True

    async def search_mikan_anime(self, query: str) -> Optional[str]:
        """è®¿é—® Mikanani æœç´¢å¹¶è§£æç»“æœ"""
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._get_cache_key(query)
            self._cleanup_cache()

            if cache_key in self._cache and self._is_cache_valid(self._cache[cache_key]):
                _log.info(f"ç¼“å­˜å‘½ä¸­: {query}")
                self._stats["cache_hits"] += 1
                return self._cache[cache_key]['data']

            self._stats["cache_misses"] += 1

            # æ„å»ºæœç´¢URL
            base_url = "https://mikanani.me/Home/Search"
            search_url = f"{base_url}?searchstr={quote(query)}"

            # è·å–ä»£ç†é…ç½®
            proxy_config = get_config("proxy", {})
            proxy = None
            if isinstance(proxy_config, dict) and proxy_config.get("enabled", False):
                proxy = proxy_config.get("http", "")
            elif isinstance(proxy_config, str) and proxy_config:
                proxy = proxy_config

            _log.info(f"æœç´¢ç•ªå‰§: {query}, URL: {search_url}")

            # å‘é€HTTPè¯·æ±‚
            async with self._session.get(search_url, proxy=proxy) as response:
                if response.status == 200:
                    html_content = await response.text()

                    # ç¼“å­˜ç»“æœ
                    self._cache[cache_key] = {
                        'data': html_content,
                        'timestamp': time.time()
                    }

                    _log.info(f"æœç´¢æˆåŠŸ: {query}, å“åº”å¤§å°: {len(html_content)} å­—ç¬¦")
                    return html_content
                else:
                    _log.warning(f"HTTPè¯·æ±‚å¤±è´¥: çŠ¶æ€ç  {response.status}")
                    await self.api.post_group_msg(
                        self.event.group_id,
                        text=f"æœç´¢å¤±è´¥ï¼ŒæœåŠ¡å™¨è¿”å›çŠ¶æ€ç : {response.status}"
                    )
                    return None

        except asyncio.TimeoutError:
            _log.warning(f"æœç´¢è¶…æ—¶: {query}")
            await self.api.post_group_msg(
                self.event.group_id,
                text="æœç´¢è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
            )
            return None

        except aiohttp.ClientError as e:
            _log.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")
            await self.api.post_group_msg(
                self.event.group_id,
                text=f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)[:100]}..."
            )
            return None

        except Exception as e:
            _log.error(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            await self.api.post_group_msg(
                self.event.group_id,
                text="æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            )
            return None

    def parse_mikan_results(self, html_content: str) -> List[Dict[str, str]]:
        """è§£æ Mikanani æœç´¢ç»“æœé¡µé¢"""
        results = []

        try:
            soup = BeautifulSoup(html_content, "lxml")
            search_result_elements = soup.find_all("tr", class_="js-search-results-row")

            if not search_result_elements:
                _log.info("æœªæ‰¾åˆ°æœç´¢ç»“æœå…ƒç´ ")
                return []

            _log.info(f"æ‰¾åˆ° {len(search_result_elements)} ä¸ªæœç´¢ç»“æœ")

            for i, result_element in enumerate(search_result_elements[:6]):  # é™åˆ¶æœ€å¤šè¿”å› 6 ä¸ªç»“æœ
                try:
                    # æå–ç•ªå‰§ä¿¡æ¯
                    title_element = result_element.find("a", class_="magnet-link-wrap")
                    title = title_element.get_text(strip=True) if title_element else "æ— æ ‡é¢˜"
                    link = "https://mikanani.me" + title_element["href"] if title_element and title_element.has_attr("href") else "æ— é“¾æ¥"

                    magnet_element = result_element.find("a", class_="js-magnet")
                    magnet_link_full = magnet_element["data-clipboard-text"] if magnet_element and magnet_element.has_attr("data-clipboard-text") else "æ— ç£åŠ›é“¾æ¥"
                    magnet_link = magnet_link_full.split('&')[0] if '&' in magnet_link_full else magnet_link_full

                    # æå–æ–‡ä»¶å¤§å°ä¿¡æ¯
                    size_element = result_element.find("td", class_="size")
                    file_size = size_element.get_text(strip=True) if size_element else "æœªçŸ¥å¤§å°"

                    # æå–å‘å¸ƒæ—¶é—´
                    date_element = result_element.find("td", class_="date")
                    publish_date = date_element.get_text(strip=True) if date_element else "æœªçŸ¥æ—¶é—´"

                    # æ ¼å¼åŒ–ç»“æœ
                    result_data = {
                        "title": title,
                        "link": link,
                        "magnet": magnet_link,
                        "size": file_size,
                        "date": publish_date
                    }

                    results.append(result_data)
                    _log.debug(f"è§£æç»“æœ {i+1}: {title[:50]}...")

                except Exception as e:
                    _log.warning(f"è§£æç¬¬ {i+1} ä¸ªç»“æœå¤±è´¥: {e}")
                    continue

            _log.info(f"æˆåŠŸè§£æ {len(results)} ä¸ªç»“æœ")
            return results

        except Exception as e:
            _log.error(f"è§£æHTMLå†…å®¹å¤±è´¥: {e}")
            return []

    async def _send_stats(self, event: GroupMessage):
        """å‘é€ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_hit_rate = 0
            if self._stats["cache_hits"] + self._stats["cache_misses"] > 0:
                cache_hit_rate = self._stats["cache_hits"] / (self._stats["cache_hits"] + self._stats["cache_misses"]) * 100

            success_rate = 0
            if self._stats["total_searches"] > 0:
                success_rate = self._stats["successful_searches"] / self._stats["total_searches"] * 100

            stats_text = (
                f"ğŸ“Š èœœæŸ‘ç•ªå‰§æœç´¢ç»Ÿè®¡\n\n"
                f"ğŸ” æ€»æœç´¢æ¬¡æ•°: {self._stats['total_searches']}\n"
                f"âœ… æˆåŠŸæ¬¡æ•°: {self._stats['successful_searches']}\n"
                f"âŒ å¤±è´¥æ¬¡æ•°: {self._stats['failed_searches']}\n"
                f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%\n\n"
                f"ğŸ’¾ ç¼“å­˜ç»Ÿè®¡:\n"
                f"ğŸ¯ ç¼“å­˜å‘½ä¸­: {self._stats['cache_hits']}\n"
                f"ğŸ”„ ç¼“å­˜æœªå‘½ä¸­: {self._stats['cache_misses']}\n"
                f"ğŸ“Š ç¼“å­˜å‘½ä¸­ç‡: {cache_hit_rate:.1f}%\n\n"
                f"âš™ï¸ ç³»ç»Ÿä¿¡æ¯:\n"
                f"ğŸ•’ ç¼“å­˜TTL: {self._cache_ttl}ç§’\n"
                f"ğŸ“¦ å½“å‰ç¼“å­˜æ¡ç›®: {len(self._cache)}\n"
                f"â±ï¸ è¯·æ±‚é—´éš”é™åˆ¶: {self._rate_limit_interval}ç§’"
            )

            await self.api.post_group_msg(event.group_id, text=stats_text)

        except Exception as e:
            _log.error(f"å‘é€ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            await self.api.post_group_msg(
                event.group_id,
                text="è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            )

    async def send_comics_forward(self, event: GroupMessage, comics: List[Dict[str, str]]):
        """åˆå¹¶è½¬å‘ç•ªå‰§ä¿¡æ¯"""
        try:
            messages = []
            bot_name = get_config("bot_name", "èœœæŸ‘æœç´¢åŠ©æ‰‹")

            # æ·»åŠ æœç´¢ç»“æœå¤´éƒ¨ä¿¡æ¯
            header_content = (
                f"ğŸ” èœœæŸ‘ç•ªå‰§æœç´¢ç»“æœ\n\n"
                f"ğŸ“Š æ‰¾åˆ° {len(comics)} ä¸ªç»“æœ\n"
                f"ğŸ•’ æœç´¢æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"ğŸ’¡ ç‚¹å‡»ç£åŠ›é“¾æ¥å¯ç›´æ¥ä¸‹è½½"
            )

            messages.append({
                "type": "node",
                "data": {
                    "nickname": f"{bot_name}",
                    "user_id": str(event.self_id),
                    "content": header_content
                }
            })

            # æ·»åŠ æ¯ä¸ªæœç´¢ç»“æœ
            for i, comic in enumerate(comics, 1):
                content = (
                    f"ğŸ“º ç•ªå‰§ {i}: {comic['title']}\n\n"
                    f"ğŸ”— è¯¦æƒ…é¡µé¢: {comic['link']}\n"
                    f"ğŸ§² ç£åŠ›é“¾æ¥: {comic['magnet']}\n"
                    f"ğŸ“¦ æ–‡ä»¶å¤§å°: {comic.get('size', 'æœªçŸ¥')}\n"
                    f"ğŸ“… å‘å¸ƒæ—¶é—´: {comic.get('date', 'æœªçŸ¥')}"
                )

                messages.append({
                    "type": "node",
                    "data": {
                        "nickname": f"{bot_name} - ç»“æœ{i}",
                        "user_id": str(event.self_id),
                        "content": content
                    }
                })

            # æ·»åŠ ä½¿ç”¨æç¤º
            footer_content = (
                "ğŸ’¡ ä½¿ç”¨æç¤º:\n"
                "â€¢ å¤åˆ¶ç£åŠ›é“¾æ¥åˆ°ä¸‹è½½å·¥å…·\n"
                "â€¢ ç‚¹å‡»è¯¦æƒ…é¡µé¢æŸ¥çœ‹æ›´å¤šä¿¡æ¯\n"
                "â€¢ å‘é€ /ç•ªå‰§ç»Ÿè®¡ æŸ¥çœ‹æœç´¢ç»Ÿè®¡\n"
                "â€¢ å‘é€ /ç•ªå‰§å¸®åŠ© æŸ¥çœ‹è¯¦ç»†å¸®åŠ©"
            )

            messages.append({
                "type": "node",
                "data": {
                    "nickname": f"{bot_name} - æç¤º",
                    "user_id": str(event.self_id),
                    "content": footer_content
                }
            })

            await send_group_forward_msg_ws(
                group_id=event.group_id,
                content=messages
            )

            _log.info(f"æˆåŠŸå‘é€ {len(comics)} ä¸ªæœç´¢ç»“æœçš„åˆå¹¶è½¬å‘æ¶ˆæ¯")

        except Exception as e:
            _log.error(f"å‘é€åˆå¹¶è½¬å‘æ¶ˆæ¯å¤±è´¥: {e}")
            # é™çº§ä¸ºæ™®é€šæ–‡æœ¬æ¶ˆæ¯
            await self._send_results_as_text(event, comics)

    async def _send_results_as_text(self, event: GroupMessage, comics: List[Dict[str, str]]):
        """é™çº§å‘é€æ™®é€šæ–‡æœ¬ç»“æœ"""
        try:
            if not comics:
                await self.api.post_group_msg(event.group_id, text="æœªæ‰¾åˆ°ç›¸å…³ç•ªå‰§")
                return

            text_results = f"ğŸ” æ‰¾åˆ° {len(comics)} ä¸ªç•ªå‰§ç»“æœ:\n\n"

            for i, comic in enumerate(comics[:3], 1):  # æ–‡æœ¬æ¨¡å¼åªæ˜¾ç¤ºå‰3ä¸ª
                text_results += (
                    f"{i}. {comic['title']}\n"
                    f"   å¤§å°: {comic.get('size', 'æœªçŸ¥')}\n"
                    f"   æ—¶é—´: {comic.get('date', 'æœªçŸ¥')}\n\n"
                )

            if len(comics) > 3:
                text_results += f"... è¿˜æœ‰ {len(comics) - 3} ä¸ªç»“æœ\n\n"

            text_results += "ğŸ’¡ å‘é€ /ç•ªå‰§ç»Ÿè®¡ æŸ¥çœ‹æœç´¢ç»Ÿè®¡"

            await self.api.post_group_msg(event.group_id, text=text_results)
            _log.info("å·²é™çº§ä¸ºæ–‡æœ¬æ¶ˆæ¯å‘é€æœç´¢ç»“æœ")

        except Exception as e:
            _log.error(f"å‘é€æ–‡æœ¬ç»“æœå¤±è´¥: {e}")
            await self.api.post_group_msg(
                event.group_id,
                text="å‘é€æœç´¢ç»“æœå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            )

    @bot.group_event()
    async def handle_group_message(self, event: GroupMessage):
        """å¤„ç†ç¾¤æ¶ˆæ¯äº‹ä»¶"""
        self.event = event
        raw_message = event.raw_message.strip()

        try:
            # ç•ªå‰§æœç´¢å‘½ä»¤
            search_match = re.match(r"^/ç•ªå‰§æœç´¢\s*(.*)$", raw_message)
            if search_match:
                await self._handle_search_command(event, search_match.group(1).strip())
                return

            # ç»Ÿè®¡å‘½ä»¤
            if raw_message in ["/ç•ªå‰§ç»Ÿè®¡", "/èœœæŸ‘ç»Ÿè®¡"]:
                await self._send_stats(event)
                return

            # å¸®åŠ©å‘½ä»¤
            if raw_message in ["/ç•ªå‰§å¸®åŠ©", "/èœœæŸ‘å¸®åŠ©"]:
                await self._send_help(event)
                return

        except Exception as e:
            _log.error(f"å¤„ç†ç¾¤æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            await self.api.post_group_msg(
                event.group_id,
                text="å¤„ç†å‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            )

    async def _handle_search_command(self, event: GroupMessage, query: str):
        """å¤„ç†æœç´¢å‘½ä»¤"""
        try:
            # æ£€æŸ¥æœç´¢å†…å®¹
            if not query:
                await self.api.post_group_msg(
                    event.group_id,
                    text="è¯·è¾“å…¥æœç´¢å†…å®¹ï¼Œä¾‹å¦‚ï¼š/ç•ªå‰§æœç´¢ å¼‚ä¸–ç•Œ"
                )
                return

            # æ£€æŸ¥é¢‘ç‡é™åˆ¶
            if not self._check_rate_limit(event.user_id):
                await self.api.post_group_msg(
                    event.group_id,
                    text=f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç­‰å¾… {self._rate_limit_interval} ç§’åå†è¯•"
                )
                return

            # æ›´æ–°ç»Ÿè®¡
            self._stats["total_searches"] += 1

            _log.info(f"ç”¨æˆ· {event.user_id} æœç´¢ç•ªå‰§: {query}")
            await self.api.post_group_msg(event.group_id, text="ğŸ” æ­£åœ¨æœç´¢ï¼Œè¯·ç¨å€™...")

            # æ‰§è¡Œæœç´¢
            results = await self.search_mikan_anime(query)
            if results is None:
                self._stats["failed_searches"] += 1
                return

            # è§£æç»“æœ
            parsed_results = self.parse_mikan_results(results)
            if parsed_results:
                self._stats["successful_searches"] += 1
                await self.send_comics_forward(event, parsed_results)
                _log.info(f"æœç´¢æˆåŠŸ: {query}, è¿”å› {len(parsed_results)} ä¸ªç»“æœ")
            else:
                self._stats["failed_searches"] += 1
                await self.api.post_group_msg(
                    event.group_id,
                    text="ğŸ˜” æœªæ‰¾åˆ°ç›¸å…³ç•ªå‰§ï¼Œè¯·å°è¯•å…¶ä»–å…³é”®è¯"
                )
                _log.info(f"æœç´¢æ— ç»“æœ: {query}")

        except Exception as e:
            self._stats["failed_searches"] += 1
            _log.error(f"æœç´¢å‘½ä»¤å¤„ç†å¤±è´¥: {e}")
            await self.api.post_group_msg(
                event.group_id,
                text="æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•"
            )

    async def _send_help(self, event: GroupMessage):
        """å‘é€å¸®åŠ©ä¿¡æ¯"""
        try:
            help_text = (
                f"ğŸŠ èœœæŸ‘ç•ªå‰§æœç´¢ v{self.version}\n\n"
                "ğŸ“‹ å¯ç”¨å‘½ä»¤:\n"
                "â€¢ /ç•ªå‰§æœç´¢ <å…³é”®è¯> - æœç´¢ç•ªå‰§èµ„æº\n"
                "â€¢ /ç•ªå‰§ç»Ÿè®¡ - æŸ¥çœ‹æœç´¢ç»Ÿè®¡\n"
                "â€¢ /ç•ªå‰§å¸®åŠ© - æ˜¾ç¤ºæ­¤å¸®åŠ©\n\n"
                "ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:\n"
                "â€¢ /ç•ªå‰§æœç´¢ å¼‚ä¸–ç•Œ\n"
                "â€¢ /ç•ªå‰§æœç´¢ é¬¼ç­ä¹‹åˆƒ\n"
                "â€¢ /ç•ªå‰§æœç´¢ è¿›å‡»çš„å·¨äºº\n\n"
                "âš ï¸ æ³¨æ„äº‹é¡¹:\n"
                f"â€¢ è¯·æ±‚é—´éš”: {self._rate_limit_interval}ç§’\n"
                f"â€¢ ç¼“å­˜æ—¶é—´: {self._cache_ttl//60}åˆ†é’Ÿ\n"
                "â€¢ æ”¯æŒä¸­æ–‡å’Œæ—¥æ–‡æœç´¢\n"
                "â€¢ ç»“æœåŒ…å«ç£åŠ›é“¾æ¥å’Œè¯¦æƒ…é¡µé¢"
            )

            await self.api.post_group_msg(event.group_id, text=help_text)

        except Exception as e:
            _log.error(f"å‘é€å¸®åŠ©ä¿¡æ¯å¤±è´¥: {e}")
            await self.api.post_group_msg(
                event.group_id,
                text="è·å–å¸®åŠ©ä¿¡æ¯å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
            )
