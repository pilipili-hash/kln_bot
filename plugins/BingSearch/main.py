import aiohttp
import asyncio
import time
from bs4 import BeautifulSoup
from ncatbot.plugin import BasePlugin, CompatibleEnrollment
from ncatbot.core.message import GroupMessage
from urllib.parse import quote
from PluginManager.plugin_manager import feature_required
from typing import List, Dict, Any, Optional
from datetime import datetime
import re

# å¯¼å…¥æ—¥å¿—å’Œé…ç½®
try:
    from ncatbot.utils.logger import get_log
except ImportError:
    try:
        from ncatbot.utils import get_log
    except ImportError:
        import logging
        def get_log():
            return logging.getLogger(__name__)

try:
    from utils.config_manager import get_config
except ImportError:
    def get_config(key, default=None):
        config_defaults = {
            "bot_name": "NCatBot",
            "bt_uin": 123456
        }
        return config_defaults.get(key, default)

bot = CompatibleEnrollment

class BingSearch(BasePlugin):
    name = "BingSearch"  # æ’ä»¶åç§°
    version = "2.0.0"  # æ’ä»¶ç‰ˆæœ¬

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.logger = get_log()
        self.bot_name = get_config("bot_name", "NCatBot")
        self.bot_uin = get_config("bt_uin", 123456)

        # ç¼“å­˜æœºåˆ¶
        self.cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜

        # è¯·æ±‚é™åˆ¶
        self.last_request_time = {}
        self.request_interval = 2  # 2ç§’é—´éš”

    def _get_cache_key(self, query: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        return f"bing_search_{hash(query.lower())}"

    def _is_cache_valid(self, cache_key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if cache_key not in self.cache:
            return False

        cache_time, _ = self.cache[cache_key]
        return time.time() - cache_time < self.cache_ttl

    def _get_cached_result(self, cache_key: str) -> Optional[str]:
        """è·å–ç¼“å­˜ç»“æœ"""
        if self._is_cache_valid(cache_key):
            _, result = self.cache[cache_key]
            return result
        return None

    def _set_cache(self, cache_key: str, result: str):
        """è®¾ç½®ç¼“å­˜"""
        self.cache[cache_key] = (time.time(), result)

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        current_time = time.time()
        expired_keys = [
            key for key, (cache_time, _) in self.cache.items()
            if current_time - cache_time > self.cache_ttl
        ]
        for key in expired_keys:
            del self.cache[key]

    async def fetch_bing_results(self, query: str) -> str:
        """è®¿é—® Bing æœç´¢å¹¶è§£æç»“æœ"""
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(query)
        cached_result = self._get_cached_result(cache_key)
        if cached_result:
            self.logger.info(f"è¿”å›ç¼“å­˜çš„æœç´¢ç»“æœ: {query}")
            return cached_result

        search_url = f"https://cn.bing.com/search?q={quote(query)}"
        headers = {
            "User-Agent": ("Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                           "AppleWebKit/537.36 (KHTML, like Gecko) "
                           "Chrome/120.0.6099.110 Safari/537.36"),
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Referer": "https://www.bing.com/",
            "DNT": "1",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }

        try:
            # ä½¿ç”¨å¼‚æ­¥HTTPè¯·æ±‚
            timeout = aiohttp.ClientTimeout(total=15, connect=5)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(search_url, headers=headers) as response:
                    if response.status == 200:
                        html_content = await response.text()
                        result = self.parse_bing_results(html_content)

                        # ç¼“å­˜ç»“æœ
                        self._set_cache(cache_key, result)
                        return result
                    else:
                        error_msg = f"âŒ Bingæœç´¢è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}"
                        self.logger.error(error_msg)
                        return error_msg

        except asyncio.TimeoutError:
            error_msg = "âŒ Bingæœç´¢è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åå†è¯•"
            self.logger.error(f"Bingæœç´¢è¶…æ—¶: {query}")
            return error_msg
        except Exception as e:
            error_msg = f"âŒ Bingæœç´¢è¯·æ±‚å¤±è´¥: {str(e)}"
            self.logger.error(f"Bingæœç´¢å¼‚å¸¸: {e}")
            return error_msg

    def _extract_title_and_link(self, result_element):
        """æå–æ ‡é¢˜å’Œé“¾æ¥çš„é€šç”¨æ–¹æ³•"""
        title = "æ— æ ‡é¢˜"
        link = "æ— é“¾æ¥"

        title_element = result_element.find("h2")
        if title_element:
            a_tag = title_element.find("a")
            if a_tag and a_tag.get("href"):
                title = a_tag.get_text(strip=True)
                link = a_tag.get("href").strip()
        else:
            a_tag = result_element.find("a", class_="tilk")
            if a_tag and a_tag.get("href"):
                title = a_tag.get_text(strip=True)
                link = a_tag.get("href").strip()
            else:
                a_tag = result_element.find("a", href=True)
                if a_tag:
                    title = a_tag.get_text(strip=True)
                    link = a_tag.get("href").strip()

        return title, link

    def _extract_description(self, result_element):
        """æå–æè¿°çš„é€šç”¨æ–¹æ³•"""
        description = "æ— æè¿°"
        description_found = False

        paragraph_tags = result_element.find_all("p")
        for p_tag in paragraph_tags:
            classes = p_tag.get("class", [])
            if any("b_lineclamp" in cls for cls in classes):
                description = p_tag.get_text(strip=True)
                description_found = True
                break

        if not description_found:
            caption_div = result_element.find("div", class_="b_caption")
            if caption_div:
                p_tag = caption_div.find("p")
                if p_tag:
                    description = p_tag.get_text(strip=True)
                    description_found = True

        if not description_found:
            attribution_div = result_element.find("div", class_="b_attribution")
            if attribution_div:
                description = attribution_div.get_text(strip=True)
                description_found = True

        return description

    def parse_bing_results(self, html_content: str) -> str:
        """è§£æ Bing æœç´¢ç»“æœé¡µé¢"""
        try:
            results = []
            soup = BeautifulSoup(html_content, "lxml")
            search_result_elements = soup.find_all("li", class_="b_algo")

            if not search_result_elements:
                self.logger.warning("æœªæ‰¾åˆ°Bingæœç´¢ç»“æœ")
                return "âŒ æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"

            max_results = 5  # é™åˆ¶æœ€å¤šè¿”å› 5 ä¸ªç»“æœ
            for index, result_element in enumerate(search_result_elements[:max_results], start=1):
                try:
                    # æå–æ ‡é¢˜å’Œé“¾æ¥
                    title, link = self._extract_title_and_link(result_element)

                    # æå–æè¿°
                    description = self._extract_description(result_element)

                    # éªŒè¯ç»“æœæœ‰æ•ˆæ€§
                    if title != "æ— æ ‡é¢˜" and link != "æ— é“¾æ¥":
                        results.append({
                            "index": index,
                            "title": title,
                            "link": link,
                            "description": description
                        })

                except Exception as e:
                    self.logger.error(f"è§£æç¬¬{index}ä¸ªæœç´¢ç»“æœå¤±è´¥: {e}")
                    continue

            if not results:
                return "âŒ æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"

            return self._format_search_results(results)

        except Exception as e:
            self.logger.error(f"è§£æBingæœç´¢ç»“æœå¤±è´¥: {e}")
            return "âŒ æœç´¢ç»“æœè§£æå¤±è´¥ï¼Œè¯·ç¨åå†è¯•"

    def _format_search_results(self, results: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºç¾è§‚çš„æ–‡æœ¬"""
        if not results:
            return "âŒ æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"

        # æ„å»ºæ ‡é¢˜
        header = f"ğŸ” Bingæœç´¢ç»“æœ (å…±{len(results)}æ¡)\n"
        header += f"ğŸ“… æœç´¢æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}\n"
        header += "=" * 40 + "\n\n"

        # æ„å»ºç»“æœåˆ—è¡¨
        result_lines = []
        for result in results:
            result_text = f"ğŸ“Œ {result['index']}. {result['title']}\n"
            result_text += f"ğŸ”— {result['link']}\n"

            # å¤„ç†æè¿°ï¼Œé™åˆ¶é•¿åº¦
            description = result['description']
            if len(description) > 100:
                description = description[:100] + "..."
            result_text += f"ğŸ“ {description}\n"

            result_lines.append(result_text)

        # æ·»åŠ ä½¿ç”¨æç¤º
        footer = "\n" + "=" * 40 + "\n"
        footer += "ğŸ’¡ ç‚¹å‡»é“¾æ¥æŸ¥çœ‹è¯¦ç»†å†…å®¹\n"
        footer += "ğŸ”„ å‘é€ /bing [å…³é”®è¯] è¿›è¡Œæ–°æœç´¢"

        return header + "\n".join(result_lines) + footer

    def _check_request_limit(self, user_id: int) -> bool:
        """æ£€æŸ¥ç”¨æˆ·è¯·æ±‚é¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        if user_id in self.last_request_time:
            time_diff = current_time - self.last_request_time[user_id]
            if time_diff < self.request_interval:
                return False

        self.last_request_time[user_id] = current_time
        return True

    def _get_remaining_cooldown(self, user_id: int) -> int:
        """è·å–å‰©ä½™å†·å´æ—¶é—´"""
        if user_id not in self.last_request_time:
            return 0

        current_time = time.time()
        time_diff = current_time - self.last_request_time[user_id]
        remaining = self.request_interval - time_diff
        return max(0, int(remaining))

    @bot.group_event()
    @feature_required("Bingæœç´¢", "/bing")
    async def handle_group_message(self, event: GroupMessage):
        """å¤„ç†ç¾¤æ¶ˆæ¯äº‹ä»¶"""
        raw_message = event.raw_message.strip()
        user_id = event.user_id
        group_id = event.group_id

        # åŒ¹é…æœç´¢å‘½ä»¤
        match = re.match(r"^/bing\s*(.*)$", raw_message, re.IGNORECASE)
        if not match:
            return

        query = match.group(1).strip()

        # æ£€æŸ¥æœç´¢å†…å®¹
        if not query:
            help_text = (
                "ğŸ” Bingæœç´¢ä½¿ç”¨è¯´æ˜\n\n"
                "ğŸ“ å‘½ä»¤æ ¼å¼ï¼š/bing [æœç´¢å†…å®¹]\n"
                "ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹ï¼š\n"
                "â€¢ /bing æç™½\n"
                "â€¢ /bing Pythonæ•™ç¨‹\n"
                "â€¢ /bing ä»Šæ—¥æ–°é—»\n\n"
                "âš ï¸ æ³¨æ„ï¼šæœç´¢é—´éš”ä¸º2ç§’"
            )
            await self.api.post_group_msg(group_id, text=help_text)
            return

        # æ£€æŸ¥è¯·æ±‚é¢‘ç‡é™åˆ¶
        if not self._check_request_limit(user_id):
            remaining = self._get_remaining_cooldown(user_id)
            await self.api.post_group_msg(
                group_id,
                text=f"â° æœç´¢è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç­‰å¾… {remaining} ç§’åå†è¯•"
            )
            return

        # éªŒè¯æœç´¢å†…å®¹é•¿åº¦
        if len(query) > 100:
            await self.api.post_group_msg(
                group_id,
                text="âŒ æœç´¢å†…å®¹è¿‡é•¿ï¼Œè¯·æ§åˆ¶åœ¨100å­—ç¬¦ä»¥å†…"
            )
            return

        try:
            # å‘é€æœç´¢æç¤º
            await self.api.post_group_msg(
                group_id,
                text=f"ğŸ” æ­£åœ¨æœç´¢ã€Œ{query}ã€ï¼Œè¯·ç¨å€™..."
            )

            # æ‰§è¡Œæœç´¢
            results = await self.fetch_bing_results(query)

            # å‘é€æœç´¢ç»“æœ
            await self.api.post_group_msg(group_id, text=results)

            self.logger.info(f"ç”¨æˆ· {user_id} åœ¨ç¾¤ {group_id} æœç´¢: {query}")

        except Exception as e:
            self.logger.error(f"å¤„ç†Bingæœç´¢è¯·æ±‚å¤±è´¥: {e}")
            await self.api.post_group_msg(
                group_id,
                text="âŒ æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•"
            )

    async def on_load(self):
        """æ’ä»¶åŠ è½½æ—¶çš„åˆå§‹åŒ–"""
        self.logger.info(f"{self.name} æ’ä»¶å·²åŠ è½½")
        self.logger.info(f"æ’ä»¶ç‰ˆæœ¬: {self.version}")
        self.logger.info("Bingæœç´¢åŠŸèƒ½å·²å¯ç”¨")

        # æ¸…ç†ç¼“å­˜å’Œè¯·æ±‚è®°å½•
        self.cache.clear()
        self.last_request_time.clear()

    async def on_unload(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†"""
        self.cache.clear()
        self.last_request_time.clear()
        self.logger.info(f"{self.name} æ’ä»¶å·²å¸è½½")
